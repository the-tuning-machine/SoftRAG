=== RAG Benchmark with Full Corpus Retrieval ===

Loading MultiHopRAG dataset (train)...
Loaded 434 examples
Built corpus with 470 unique documents

Sample Corpus Documents:
['Before his fall, Bankman-Fried made himself out to be the Good Boy of crypto — the trustworthy face of a sometimes-shady industry.', 'The highly anticipated criminal trial for Sam Bankman-Fried, former CEO of bankrupt crypto exchange FTX, started Tuesday to determine whether he’s guilty of seven counts of fraud and conspiracy.', 'The prosecution painted Bankman-Fried as someone who knowingly committed fraud to achieve great wealth, power and influence, while the defense countered that the FTX founder acted in good faith, never meant to commit fraud or steal and basically got in over his head.', 'No apartment in New York City has ever sold for close to that amount, James said.', 'The prosecution argues that was to mask a drop in the value of one of his other properties.']
[RAGExample(query_id=0, query='Who is the individual associated with the cryptocurrency industry facing a criminal trial on fraud and conspiracy charges, as reported by both The Verge and TechCrunch, and is accused by prosecutors of committing fraud for personal gain?', relevant_doc_ids={0, 1, 2}), RAGExample(query_id=1, query="Which individual is implicated in both inflating the value of a Manhattan apartment to a figure not yet achieved in New York City's real estate history, according to 'Fortune', and is also accused of adjusting this apartment's valuation to compensate for a loss in another asset's worth, as reported by 'The Age'?", relevant_doc_ids={3, 4}), RAGExample(query_id=2, query='Who is the figure associated with generative AI technology whose departure from OpenAI was considered shocking according to Fortune, and is also the subject of a prevailing theory suggesting a lack of full truthfulness with the board as reported by TechCrunch?', relevant_doc_ids={5, 6}), RAGExample(query_id=3, query='Do the TechCrunch article on software companies and the Hacker News article on The Epoch Times both report an increase in revenue related to payment and subscription models, respectively?', relevant_doc_ids={8, 7}), RAGExample(query_id=4, query="Which online betting platform provides a welcome bonus of up to $1000 in bonus bets for new customers' first losses, runs NBA betting promotions, and is anticipated to extend the same sign-up offer to new users in Vermont, as reported by both CBSSports.com and Sporting News?", relevant_doc_ids={9, 10, 11})]

Train examples: 347
Test examples: 87
Corpus size: 470 documents

Creating RAG model...
Loading embedding model: all-MiniLM-L6-v2...
Loading cross-encoder: cross-encoder/ms-marco-MiniLM-L-6-v2...
Embedding corpus of 470 documents...
Corpus embedded: torch.Size([470, 384])
Trainable parameters: 97

=== Before Training (k=20) ===
  Evaluating 1/87
  Evaluating 11/87
  Evaluating 21/87
  Evaluating 31/87
  Evaluating 41/87
  Evaluating 51/87
  Evaluating 61/87
  Evaluating 71/87
  Evaluating 81/87

Evaluation Results:
Precision@20: 0.1236
Recall@20: 0.9234
MRR: 0.8424
NDCG@20: 0.7861

=== Training (k=20) ===
  Example 1/347
  Example 11/347
  Example 21/347
  Example 31/347
  Example 41/347
  Example 51/347
  Example 61/347
  Example 71/347
  Example 81/347
  Example 91/347
  Example 101/347
  Example 111/347
  Example 121/347
  Example 131/347
  Example 141/347
  Example 151/347
  Example 161/347
  Example 171/347
  Example 181/347
  Example 191/347
  Example 201/347
  Example 211/347
  Example 221/347
  Example 231/347
  Example 241/347
  Example 251/347
  Example 261/347
  Example 271/347
  Example 281/347
  Example 291/347
  Example 301/347
  Example 311/347
  Example 321/347
  Example 331/347
  Example 341/347
Epoch 1/5, Loss: 4.8527, Recall@20: 0.8788
  Example 1/347
  Example 11/347
  Example 21/347
  Example 31/347
  Example 41/347
  Example 51/347
  Example 61/347
  Example 71/347
  Example 81/347
  Example 91/347
  Example 101/347
  Example 111/347
  Example 121/347
  Example 131/347
  Example 141/347
  Example 151/347
  Example 161/347
  Example 171/347
  Example 181/347
  Example 191/347
  Example 201/347
  Example 211/347
  Example 221/347
  Example 231/347
  Example 241/347
  Example 251/347
  Example 261/347
  Example 271/347
  Example 281/347
  Example 291/347
  Example 301/347
  Example 311/347
  Example 321/347
  Example 331/347
  Example 341/347
Epoch 2/5, Loss: 4.3214, Recall@20: 0.8788
  Example 1/347
  Example 11/347
  Example 21/347
  Example 31/347
  Example 41/347
  Example 51/347
  Example 61/347
  Example 71/347
  Example 81/347
  Example 91/347
  Example 101/347
  Example 111/347
  Example 121/347
  Example 131/347
  Example 141/347
  Example 151/347
  Example 161/347
  Example 171/347
  Example 181/347
  Example 191/347
  Example 201/347
  Example 211/347
  Example 221/347
  Example 231/347
  Example 241/347
  Example 251/347
  Example 261/347
  Example 271/347
  Example 281/347
  Example 291/347
  Example 301/347
  Example 311/347
  Example 321/347
  Example 331/347
  Example 341/347
Epoch 3/5, Loss: 4.2917, Recall@20: 0.8788
  Example 1/347
  Example 11/347
  Example 21/347
  Example 31/347
  Example 41/347
  Example 51/347
  Example 61/347
  Example 71/347
  Example 81/347
  Example 91/347
  Example 101/347
  Example 111/347
  Example 121/347
  Example 131/347
  Example 141/347
  Example 151/347
  Example 161/347
  Example 171/347
  Example 181/347
  Example 191/347
  Example 201/347
  Example 211/347
  Example 221/347
  Example 231/347
  Example 241/347
  Example 251/347
  Example 261/347
  Example 271/347
  Example 281/347
  Example 291/347
  Example 301/347
  Example 311/347
  Example 321/347
  Example 331/347
  Example 341/347
Epoch 4/5, Loss: 4.2820, Recall@20: 0.8788
  Example 1/347
  Example 11/347
  Example 21/347
  Example 31/347
  Example 41/347
  Example 51/347
  Example 61/347
  Example 71/347
  Example 81/347
  Example 91/347
  Example 101/347
  Example 111/347
  Example 121/347
  Example 131/347
  Example 141/347
  Example 151/347
  Example 161/347
  Example 171/347
  Example 181/347
  Example 191/347
  Example 201/347
  Example 211/347
  Example 221/347
  Example 231/347
  Example 241/347
  Example 251/347
  Example 261/347
  Example 271/347
  Example 281/347
  Example 291/347
  Example 301/347
  Example 311/347
  Example 321/347
  Example 331/347
  Example 341/347
Epoch 5/5, Loss: 4.2801, Recall@20: 0.8788

=== After Training (k=20) ===
  Evaluating 1/87
  Evaluating 11/87
  Evaluating 21/87
  Evaluating 31/87
  Evaluating 41/87
  Evaluating 51/87
  Evaluating 61/87
  Evaluating 71/87
  Evaluating 81/87

Evaluation Results:
Precision@20: 0.1236
Recall@20: 0.9234
MRR: 0.8424
NDCG@20: 0.7861

=== Benchmark Complete ===
